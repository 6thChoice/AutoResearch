# 科研智能体系统 - 自然语言通信协议（Markdown 文档格式）

## 1. 概述

### 1.1 设计哲学

本系统采用**文档化通信**方式，模块间的通信通过结构化的 Markdown 文档完成。这种方式：

- **人类可读**：便于调试和理解
- **AI 友好**：大语言模型天然擅长处理 Markdown
- **自包含**：每个通信文档包含完整上下文
- **可追溯**：天然形成通信历史记录

### 1.2 文档类型

| 文档类型 | 命名约定 | 用途 |
|---------|---------|------|
| **需求文档** | `REQ-{module}-{timestamp}.md` | 向其他模块提出需求/请求 |
| **交付文档** | `DEL-{module}-{timestamp}.md` | 向其他模块交付成果 |
| **分析报告** | `ANALYSIS-{topic}-{timestamp}.md` | 分析结果和洞察 |
| **会议纪要** | `MEET-{participants}-{timestamp}.md` | 多方讨论记录 |
| **设计文档** | `DESIGN-{feature}-{timestamp}.md` | 设计方案说明 |
| **工作总结** | `SUMMARY-{phase}-{timestamp}.md` | 阶段工作总结 |

---

## 2. 文档结构标准

### 2.1 通用头部模板

每个通信文档必须包含以下头部信息：

```markdown
# 文档标题

**文档类型**: [REQ|DEL|ANALYSIS|MEET|DESIGN|SUMMARY]

**发送方**: [发送模块/Agent 名称]

**接收方**: [接收模块/Agent 名称]

**时间**: [YYYY-MM-DD HH:MM:SS]

**会话ID**: [session_id]

**父文档**: [相关前置文档链接]

**优先级**: [紧急|高|中|低]

**状态**: [待处理|进行中|已完成|已拒绝]

---
```

### 2.2 内容区域模板

```markdown
## 1. 背景与上下文

[描述通信的背景、相关历史、前置条件]

## 2. 主要内容

### 2.1 [子主题1]

[具体内容，可以使用列表、表格、代码块等]

### 2.2 [子主题2]

[具体内容]

## 3. 具体需求/交付物

- [ ] [需求/交付物1]
- [ ] [需求/交付物2]

## 4. 约束条件

- [约束1]
- [约束2]

## 5. 验收标准

[如何定义成功完成]

## 6. 附件

- [文件链接或描述]

## 7. 下一步行动

[预期的后续步骤]

---

**签名**: [发送方 Agent 标识]

**关联代码**: [如有相关的代码引用]
```

---

## 3. 模块间通信示例

### 3.1 Idea 规范化模块 → 用户

**文档**: `REQ-idea-normalization-20240219-100000.md`

```markdown
# Idea 细化需求说明

**文档类型**: REQ（需求）

**发送方**: Idea 规范化模块 (Agent)

**接收方**: 用户 (Researcher)

**时间**: 2024-02-19 10:00:00

**会话ID**: session-20240219-001

**父文档**: [用户初始 Idea 提交]

**优先级**: 高

**状态**: 待处理

---

## 1. 背景与上下文

我已仔细阅读您提交的关于"动态稀疏注意力机制"的研究想法，并查阅了您提供的参考文献。经过初步分析，我认为这个 Idea 具有创新性，但需要进一步细化以确保后续实验设计的准确性。

## 2. 当前理解

根据您的描述和相关文献，我理解您的核心思路是：

> 在 Transformer 的注意力计算中引入动态稀疏性，根据输入内容自动选择需要计算注意力的 token 对，从而减少计算量。

## 3. 需要澄清的问题

为了更好地设计实验方案，我需要您补充以下信息：

### 3.1 稀疏性判断标准

**问题**: 您提到"动态稀疏"，那么稀疏性的判断标准是什么？

**选项**:
- A. 基于注意力权重的阈值（如只保留 top-k）
- B. 基于输入内容的启发式规则（如只关注相邻 token）
- C. 基于学习的门控机制（训练一个预测器）
- D. 其他方式（请描述）

**影响**: 这决定了实现的核心算法结构

### 3.2 实验范围

**问题**: 您希望在哪些任务上验证这个方法？

**建议选项**:
1. **机器翻译** (WMT14 En-De)
   - 优势: 标准 benchmark，易于对比
   - 关注点: BLEU 分数和推理速度

2. **长文档分类** (如 arXiv 论文分类)
   - 优势: 能体现长序列的优势
   - 关注点: 准确率 vs 序列长度

3. **两者都进行**
   - 优势: 全面验证
   - 风险: 实验工作量较大

### 3.3 Baseline 选择

**问题**: 您希望与哪些 baseline 对比？

我根据文献调研建议：

| Baseline | 说明 | 优先级 |
|---------|------|--------|
| Standard Transformer | 原始模型，必须对比 | 必需 |
| Sparse Transformer | 固定稀疏模式 | 建议 |
| Linformer | 线性复杂度方法 | 建议 |
| Reformer | LSH 注意力 | 可选 |

## 4. 我的初步建议

基于目前的信息，我建议采用以下实现策略：

### 策略 A: 基于 Top-k 的动态稀疏（推荐）

**思路**: 在计算注意力时，每个 query 只关注 key 集合中相似度最高的 top-k 个

**优点**:
- 实现简单，可解释性强
- 计算复杂度明确降为 O(n*k)
- 容易与标准 Transformer 对比

**风险**:
- 需要确定合适的 k 值
- 可能损失全局信息

### 策略 B: 基于内容的自适应稀疏

**思路**: 使用一个小型网络预测哪些 token 对需要计算注意力

**优点**:
- 更灵活，可能效果更好
- 符合您"动态"的要求

**风险**:
- 实现复杂
- 需要额外的训练开销

## 5. 请确认

请您：

1. **回答上述问题**（可直接在本文档上编辑回复）
2. **选择或修改实现策略**
3. **确认或调整 baseline 列表**
4. **补充任何其他要求**（如资源限制、时间节点等）

## 6. 下一步

收到您的回复后，我将：

1. 完善 Idea 的规范化描述
2. 设计详细的实验计划
3. 提交给您确认

---

**签名**: Idea-Normalization-Agent-v1

**附件**:
- [文献调研摘要](attachment-lit-review.md)
- [相关代码库分析](attachment-code-review.md)
```

---

### 3.2 用户 → Idea 规范化模块（回复）

**文档**: `DEL-user-20240219-110000.md`

```markdown
# Idea 细化回复

**文档类型**: DEL（交付/回复）

**发送方**: 用户 (Researcher)

**接收方**: Idea 规范化模块 (Agent)

**时间**: 2024-02-19 11:00:00

**会话ID**: session-20240219-001

**父文档**: [REQ-idea-normalization-20240219-100000.md]

**优先级**: 高

**状态**: 已完成

---

## 1. 问题回复

### 1.1 稀疏性判断标准

**选择**: A + C 的组合方案

**详细说明**:

我希望能实现一个两阶段方法：

```python
# 伪代码示意
def dynamic_sparse_attention(Q, K, V):
    # 阶段1: 快速筛选（固定规则）
    candidate_indices = coarse_selection(Q, K)  # 选出候选集

    # 阶段2: 精细选择（学习得到）
    attention_weights = gating_network(Q, K[candidate_indices])
    top_k_indices = topk_selection(attention_weights, k=K)

    # 计算稀疏注意力
    output = standard_attention(Q, K[top_k_indices], V[top_k_indices])
    return output
```

**动机**:
- 纯学习的方法（策略B）训练不稳定
- 纯规则的方法（策略A）不够灵活
- 组合方案可以平衡效果和效率

### 1.2 实验范围

**选择**: 先进行机器翻译（WMT14 En-De），成功后再扩展

**原因**:
- 资源有限，希望先集中验证核心想法
- WMT14 是标准 benchmark，社区认可度高

**具体要求**:
- 必须在标准测试集上进行
- 需要报告 BLEU 和推理速度
- 希望对比不同序列长度下的表现

### 1.3 Baseline 选择

**确认您的建议**:

| Baseline | 确认 | 备注 |
|---------|------|------|
| Standard Transformer | ✅ 必需 | - |
| Sparse Transformer | ✅ 建议 | 使用 strided pattern |
| Linformer | ✅ 建议 | - |
| Reformer | ❌ 可选 | 暂时跳过，实现太复杂 |

**额外要求**:
- 需要与 HuggingFace 的实现对比
- 确保所有 baseline 使用相同的训练配置

## 2. 实现策略确认

**选择**: 策略 A 的扩展版本（组合方案）

**详细需求**:

### 2.1 核心算法

1. **粗筛选**: 使用局部窗口 + 全局 token
   - 每个 query 关注：自身窗口(±w) + 特殊的全局 token([CLS], [SEP])
   - 复杂度: O(n * (2w + g))

2. **精筛选**: 学习 gating 网络
   - 在候选集中选择 top-k 进行精细注意力计算
   - k 作为超参数可调

### 2.2 技术细节

| 参数 | 建议值 | 说明 |
|------|--------|------|
| 窗口大小 w | 8-16 | 需要实验确定 |
| 全局 token 数 g | 2-4 | [CLS], [SEP] 等 |
| top-k | 32-64 | 小于窗口大小 |

## 3. 额外要求

### 3.1 资源限制

- **GPU**: 8x A100 (40GB)
- **时间**: 希望在 1 周内得到初步结果
- **代码**: 希望基于 fairseq 或 HuggingFace 实现

### 3.2 评估指标

除标准指标外，还希望统计：

- 实际计算的注意力比例（稀疏度）
- 不同长度序列的推理延迟
- 内存占用情况

## 4. 开放性建议

我对以下方面持开放态度，欢迎您的建议：

1. 是否需要先在小数据集上验证？
2. 是否需要设计消融实验验证每个组件的贡献？
3. 是否需要考虑其他应用场景的扩展性？

---

**签名**: Researcher-Zhang

**联系方式**: [如有需要进一步沟通的方式]
```

---

### 3.3 Idea 规范化模块 → 实验计划模块

**文档**: `DESIGN-idea-implementation-20240219-120000.md`

```markdown
# 规范化 Idea 与实现策略设计

**文档类型**: DESIGN（设计方案）

**发送方**: Idea 规范化模块

**接收方**: 实验计划模块

**时间**: 2024-02-19 12:00:00

**会话ID**: session-20240219-001

**父文档**:
- [用户初始 Idea](initial-idea.md)
- [用户细化回复](DEL-user-20240219-110000.md)

**优先级**: 高

**状态**: 待处理

---

## 1. Idea 规范化总结

经过与用户的多轮沟通，Idea 已规范化如下：

### 1.1 核心创新点

**名称**: 两阶段动态稀疏注意力机制 (Two-Stage Dynamic Sparse Attention, TSDSA)

**问题**: 标准 Transformer 的二次复杂度限制了长序列应用

**解决方案**:
通过粗筛选（固定规则）+ 精筛选（学习 gating）的两阶段方法，实现计算复杂度与模型效果的平衡。

### 1.2 技术方案

```
┌─────────────────────────────────────────────────────────┐
│                    TSDSA 注意力计算                      │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Input: Q, K, V                                        │
│     │                                                  │
│     ▼                                                  │
│  ┌─────────────────┐                                   │
│  │ 阶段1: 粗筛选    │  ← 固定规则                        │
│  │ • 局部窗口(±w)   │                                   │
│  │ • 全局token     │                                   │
│  └────────┬────────┘                                   │
│           ▼                                            │
│     Candidate Set (大小: 2w + g)                       │
│           │                                            │
│           ▼                                            │
│  ┌─────────────────┐                                   │
│  │ 阶段2: 精筛选    │  ← 学习gating网络                  │
│  │ • Gating Network │                                   │
│  │ • Top-k 选择    │                                   │
│  └────────┬────────┘                                   │
│           ▼                                            │
│     Top-k Selected                                     │
│           │                                            │
│           ▼                                            │
│  ┌─────────────────┐                                   │
│  │ 标准注意力计算   │                                   │
│  └────────┬────────┘                                   │
│           ▼                                            │
│     Output: Attention(Q, K_selected, V_selected)       │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 1.3 预期优势

1. **计算效率**: 复杂度从 O(n²) 降至 O(n * (2w + g) * k)
2. **效果保持**: 通过学习的 gating 保持重要注意力连接
3. **可解释性**: 可以分析 gating 网络学到了什么模式

## 2. 建议的实现策略

我设计了 3 种实现策略，推荐按优先级尝试：

### 策略 1: 组合方案（推荐，首选）

**描述**: 两阶段方法（粗筛选 + 精筛选）

**复杂度**: O(n * (2w + g) * k)

**优点**:
- 最符合用户原始想法
- 灵活性最高
- 有潜力达到最好效果

**风险**:
- 实现较复杂
- 需要调参较多

**关键组件**:
- `CoarseSelection`: 基于位置的候选集生成
- `GatingNetwork`: 轻量级网络，预测注意力重要性
- `SparseAttention`: 基于 top-k 的注意力计算

### 策略 2: 纯规则方案（保底）

**描述**: 仅使用粗筛选（窗口 + 全局 token）

**复杂度**: O(n * (2w + g))

**优点**:
- 实现简单
- 训练稳定
- 可作为 baseline

**风险**:
- 效果可能不如策略1
- 不够"动态"

### 策略 3: 纯学习方案（探索）

**描述**: 仅使用精筛选（学习选择所有 token）

**复杂度**: O(n²)（选择过程）

**优点**:
- 最灵活
- 可以学习任意稀疏模式

**风险**:
- 训练不稳定
- 实现复杂
- 可能退化为密集注意力

## 3. 实验设计建议

### 3.1 主实验

**任务**: WMT14 En-De 机器翻译

**对比方案**:
1. TSDSA-策略1 (组合方案)
2. TSDSA-策略2 (纯规则)
3. Standard Transformer (标准 baseline)
4. Sparse Transformer (稀疏 baseline)
5. Linformer (线性复杂度 baseline)

### 3.2 关键超参数

| 超参数 | 搜索空间 | 默认值 |
|--------|---------|--------|
| 窗口大小 w | [8, 16, 32] | 16 |
| 全局 token 数 g | [2, 4] | 2 |
| top-k | [32, 64, 128] | 64 |
| gating 网络层数 | [1, 2] | 1 |

### 3.3 评估指标

**主要指标**:
- BLEU-4 (de tokenized)

**次要指标**:
- 推理时间 (不同序列长度)
- 训练时间
- GPU 内存占用
- 实际稀疏度比例

**分析指标**:
- gating 网络的选择分布
- 注意力可视化

## 4. 约束条件

### 4.1 资源约束

- **GPU**: 8x A100 (40GB)
- **时间**: 1 周内初步结果
- **代码基础**: fairseq 或 HuggingFace

### 4.2 技术要求

- 必须与标准 Transformer 使用相同的训练配置
- 需要支持混合精度训练
- 需要可复现（设置随机种子）

### 4.3 验收标准

**最小成功标准**:
- BLEU 损失 < 1.0（相比标准 Transformer）
- 推理速度提升 ≥ 20%

**理想成功标准**:
- BLEU 持平或提升
- 推理速度提升 ≥ 50%
- 内存占用减少 ≥ 30%

## 5. 风险评估

| 风险 | 概率 | 影响 | 缓解措施 |
|------|------|------|----------|
| gating 网络训练不稳定 | 中 | 高 | 设计 fallback 到纯规则方案 |
| 效果不如预期 | 中 | 中 | 准备多个超参数配置 |
| 实现复杂度超预期 | 低 | 中 | 分阶段交付，先实现简化版 |
| 时间不足 | 中 | 中 | 优先级排序，核心功能优先 |

## 6. 下一步行动

请实验计划模块：

1. **细化实验计划**: 基于本设计，制定详细的实验步骤
2. **资源评估**: 确认资源需求是否可行
3. **时间安排**: 制定 1 周内的详细时间表
4. **风险准备**: 制定风险发生时的备选方案

---

**签名**: Idea-Normalization-Agent-v1

**附件**:
- [相关文献列表](references.md)
- [代码库调研](code-survey.md)
- [Baseline 性能参考](baseline-benchmarks.md)
```

---

### 3.4 实验计划模块 → 代码智能体（规划层）

**文档**: `REQ-experiment-plan-20240219-130000.md`

```markdown
# 实验执行需求说明

**文档类型**: REQ（需求）

**发送方**: 实验计划模块

**接收方**: 代码智能体（规划层）

**时间**: 2024-02-19 13:00:00

**会话ID**: session-20240219-001

**父文档**:
- [规范化 Idea 设计](DESIGN-idea-implementation-20240219-120000.md)

**优先级**: 高

**状态**: 待处理

---

## 1. 任务概述

基于已确认的 Idea 设计，需要完成以下实验工作：

### 1.1 实验范围

**主任务**: 在 WMT14 En-De 上验证 TSDSA 注意力机制

**包含内容**:
1. Baseline 复现（3 个 baseline）
2. TSDSA 实现（2 种策略）
3. 对比实验与评估

### 1.2 资源分配

- **计算资源**: 8x A100 (40GB)
- **存储资源**: 500GB
- **时间预算**: 7 天

## 2. 详细实验计划

### 阶段 1: 环境准备与 Baseline 复现（Day 1-2）

#### 2.1.1 环境搭建

**需求**:
- 基于 fairseq 或 HuggingFace 搭建实验框架
- 配置 WMT14 En-De 数据流水线
- 设置实验追踪（MLflow）

**验收标准**:
- [ ] 数据下载并预处理完成
- [ ] 可以运行训练脚本
- [ ] MLflow 可以记录实验

#### 2.1.2 Baseline 复现

需要复现以下 baseline：

| Baseline | 目标 BLEU | 优先级 | 预计时间 |
|---------|-----------|--------|----------|
| Standard Transformer | ~27.3 | P0 | 8h |
| Sparse Transformer | ~26.5 | P1 | 6h |
| Linformer | ~25.0 | P1 | 6h |

**验收标准**:
- [ ] 达到文献报告的性能水平（±0.5 BLEU）
- [ ] 保存可复现的训练配置
- [ ] 记录训练时间和资源使用

### 阶段 2: TSDSA 实现（Day 3-4）

#### 2.2.1 策略 2: 纯规则方案（保底）

**实现内容**:

```python
# 核心伪代码
class RuleBasedSparseAttention(nn.Module):
    def __init__(self, window_size=16, global_tokens=2):
        self.w = window_size
        self.g = global_tokens

    def forward(self, Q, K, V):
        # 构建局部窗口 mask
        local_mask = self.create_local_mask(seq_len, self.w)
        # 添加全局 token 连接
        global_mask = self.create_global_mask(seq_len, self.g)
        # 组合 mask
        mask = local_mask | global_mask
        # 标准注意力计算
        return standard_attention(Q, K, V, mask)
```

**验收标准**:
- [ ] 代码正确运行
- [ ] 复杂度符合预期 O(n * (2w + g))
- [ ] 可以正常训练

#### 2.2.2 策略 1: 组合方案（主要）

**实现内容**:

1. **CoarseSelection 模块**
   - 基于位置的候选集生成
   - 窗口 + 全局 token

2. **GatingNetwork 模块**
   - 轻量级 2 层 MLP
   - 输入: query 和 key
   - 输出: 重要性分数

3. **TwoStageSparseAttention 模块**
   - 整合粗筛选和精筛选
   - 支持 top-k 选择

**验收标准**:
- [ ] 三个模块独立测试通过
- [ ] 整体训练稳定
- [ ] 可以调整超参数

### 阶段 3: 对比实验（Day 5-6）

#### 2.3.1 超参数搜索

对关键超参数进行网格搜索：

| 超参数 | 搜索值 | 说明 |
|--------|--------|------|
| w (窗口) | 8, 16, 32 | 局部窗口大小 |
| g (全局) | 2, 4 | 全局 token 数 |
| k (top-k) | 32, 64, 128 | 精筛选保留数 |

**注意**: 使用阶段 1 保存的 baseline 镜像，避免重复训练

#### 2.3.2 完整评估

每个配置需要：
- [ ] 训练 3 个随机种子（可复现性）
- [ ] 报告平均 BLEU 和标准差
- [ ] 测量不同长度序列的推理时间
- [ ] 统计实际稀疏度比例

### 阶段 4: 分析与报告（Day 7）

#### 2.3.3 结果收集

收集所有实验结果，包括：
- 训练曲线
- 评估指标
- 资源使用日志
- 错误案例

#### 2.3.4 深度分析

- gating 网络行为分析
- 注意力可视化
- 失败案例分析

## 3. 沙盒管理策略

### 3.1 镜像保存计划

**触发条件**: 阶段 1 完成后

**保存内容**:
- 完整复现的 3 个 baseline
- 预处理的 WMT14 数据
- 训练好的模型 checkpoint

**镜像名称**: `baseline-wmt14-v1`

### 3.2 并行实验策略

从 baseline 镜像创建多个沙盒，并行运行：

```
沙盒 sb-001: 策略2 (w=16, g=2)
沙盒 sb-002: 策略1 (w=16, g=2, k=64)
沙盒 sb-003: 策略1 (w=32, g=2, k=64)
...
```

## 4. 技术要求

### 4.1 代码规范

- 使用 Python 3.8+
- 代码需要注释和文档字符串
- 关键算法需要单元测试

### 4.2 可复现性

- 设置随机种子: 42, 123, 456
- 记录所有依赖版本
- 保存训练配置

### 4.3 监控要求

- 实时记录训练 loss
- 每 epoch 保存 checkpoint
- 监控 GPU 使用和内存

## 5. 交付物

### 5.1 代码交付

- [ ] TSDSA 实现代码
- [ ] Baseline 复现代码
- [ ] 评估脚本
- [ ] 可视化脚本

### 5.2 数据交付

- [ ] 训练曲线数据
- [ ] 评估结果表格
- [ ] 对比分析图表

### 5.3 文档交付

- [ ] 实现说明文档
- [ ] 实验报告
- [ ] 使用说明

## 6. 风险应对

### 6.1 时间风险

如果进度落后，优先保证：
1. Standard Transformer baseline
2. TSDSA 策略 2（纯规则）
3. 主要超参数配置（w=16, k=64）

### 6.2 技术风险

如果实现遇到困难：
1. 及时反馈，讨论简化方案
2. 参考已有开源实现
3. 考虑使用更简单的变体

## 7. 沟通计划

- **每日同步**: 每天 18:00 汇报进度
- **关键节点**: 阶段完成时提交阶段性报告
- **紧急问题**: 立即通过同步通道沟通

---

**签名**: Experiment-Planning-Agent-v1

**附件**:
- [详细训练配置](training-config.md)
- [数据预处理脚本](data-pipeline.md)
- [评估指标计算](metrics-computation.md)
```

---

## 4. 通信文档管理

### 4.1 文档存储结构

```
./communication/
├── session-20240219-001/
│   ├── index.md                    # 会话索引
│   ├── initial-idea.md             # 初始输入
│   ├──
│   ├── 01-req-idea-normalization/  # 第一轮通信
│   │   ├── req-20240219-100000.md  # 请求
│   │   └── del-20240219-110000.md  # 回复
│   ├──
│   ├── 02-design-experiment/       # 第二轮通信
│   │   └── design-20240219-120000.md
│   ├──
│   ├── 03-req-code-execution/      # 第三轮通信
│   │   └── req-20240219-130000.md
│   └──
│   └── attachments/                # 附件文件
│       ├── lit-review.md
│       ├── code-survey.md
│       └── baseline-benchmarks.md
```

### 4.2 文档索引模板

**index.md**

```markdown
# 会话索引: session-20240219-001

## 基本信息

- **创建时间**: 2024-02-19 10:00:00
- **当前状态**: 进行中
- **当前阶段**: 代码执行阶段

## 参与方

- 用户 (Researcher-Zhang)
- Idea 规范化模块
- 实验计划模块
- 代码智能体

## 通信历史

| 轮次 | 文档 | 发送方 | 接收方 | 时间 | 状态 |
|------|------|--------|--------|------|------|
| 1 | [req-20240219-100000](01-req-idea-normalization/req-20240219-100000.md) | Idea模块 | 用户 | 10:00 | 已完成 |
| 1 | [del-20240219-110000](01-req-idea-normalization/del-20240219-110000.md) | 用户 | Idea模块 | 11:00 | 已完成 |
| 2 | [design-20240219-120000](02-design-experiment/design-20240219-120000.md) | Idea模块 | 实验计划模块 | 12:00 | 已完成 |
| 3 | [req-20240219-130000](03-req-code-execution/req-20240219-130000.md) | 实验计划模块 | 代码智能体 | 13:00 | 进行中 |

## 当前任务

- **进行中的任务**: 实验执行（阶段 1: Baseline 复现）
- **负责人**: 代码智能体（规划层）
- **预计完成**: 2024-02-20 12:00:00

## 关键决策记录

1. **实现策略**: 采用两阶段动态稀疏注意力（TSDSA）
2. **实验范围**: WMT14 En-De 机器翻译
3. **Baseline**: Standard, Sparse, Linformer

## 下一步

等待代码智能体完成阶段 1 后提交进度报告。
```

### 4.3 文档解析规范

为了便于 AI Agent 自动处理 Markdown 文档，约定以下解析规则：

```python
class MarkdownCommunicationParser:
    """Markdown 通信文档解析器"""

    def parse_header(self, doc: str) -> dict:
        """解析文档头部元数据"""
        # 提取文档类型、发送方、接收方等
        pattern = r'\*\*([^:]+)\*\*:\s*([^\n]+)'
        matches = re.findall(pattern, doc.split('---')[0])
        return {k.strip(): v.strip() for k, v in matches}

    def parse_sections(self, doc: str) -> dict:
        """解析文档章节"""
        # 按 ## 标题分割
        sections = {}
        current_section = None

        for line in doc.split('\n'):
            if line.startswith('## '):
                current_section = line[3:].strip()
                sections[current_section] = []
            elif current_section:
                sections[current_section].append(line)

        return {k: '\n'.join(v) for k, v in sections.items()}

    def extract_checklists(self, doc: str) -> list:
        """提取检查清单"""
        # 提取 - [ ] 和 - [x] 项
        pattern = r'- \[([ x])\] (.+)'
        return re.findall(pattern, doc)

    def extract_code_blocks(self, doc: str) -> list:
        """提取代码块"""
        pattern = r'```(\w+)?\n(.*?)```'
        return re.findall(pattern, doc, re.DOTALL)
```

---

## 5. 优势与最佳实践

### 5.1 自然语言通信的优势

1. **可读性强**: 人类可以直接阅读和理解通信内容
2. **上下文丰富**: 可以包含详细的背景、推理、解释
3. **灵活性高**: 不受严格格式约束，可以自由表达
4. **AI 友好**: 大语言模型天然擅长处理自然语言
5. **自文档化**: 通信过程本身就是文档

### 5.2 最佳实践

1. **结构化与自由度的平衡**
   - 使用标准模板确保关键信息不遗漏
   - 保留自然语言描述的空间

2. **清晰的章节组织**
   - 使用标题层级表示信息重要性
   - 使用列表和表格提高可读性

3. **代码与自然语言结合**
   - 算法思路用自然语言描述
   - 具体实现用代码块展示

4. **可追溯性**
   - 每个文档都引用父文档
   - 维护清晰的通信索引

5. **状态可视化**
   - 使用检查清单 [ ] 表示待办
   - 使用表格对比不同选项
   - 使用流程图展示算法

---

## 6. 工具支持

### 6.1 Markdown 处理工具

```python
# 文档创建工具
class CommunicationDocumentBuilder:
    """通信文档构建器"""

    def create_request(self, sender, receiver, content):
        doc = f"""# 请求: {content['title']}

**文档类型**: REQ

**发送方**: {sender}

**接收方**: {receiver}

**时间**: {datetime.now()}

---

## 背景

{content['background']}

## 需求

{content['requirements']}

## 验收标准

{self._format_checklist(content['criteria'])}
"""
        return doc
```

### 6.2 文档索引管理

```python
# 索引更新
class CommunicationIndex:
    def add_entry(self, doc_path, metadata):
        """添加通信记录到索引"""
        entry = {
            'path': doc_path,
            'type': metadata['type'],
            'sender': metadata['sender'],
            'receiver': metadata['receiver'],
            'timestamp': metadata['time'],
            'status': metadata['status']
        }
        self.entries.append(entry)
        self._update_index_file()
```

---

这种自然语言 + Markdown 的通信方式使系统既保持了结构化，又具有人类可理解的友好性，特别适合需要大量上下文和推理的科研场景。
